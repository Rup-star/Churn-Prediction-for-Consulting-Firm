# Run in Azure Databricks Notebook

# Import the necessary libraries
from pyspark.sql import SparkSession
from churn_model import load_data, train_model

# Load and preprocess data
processed_data = load_data("/dbfs/data/processed_data.csv")

# Train the model and evaluate accuracy
train_model(processed_data)
